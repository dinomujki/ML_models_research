{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "- We can use numpy darrays to store the matrix\n",
    "- Then for easier access and better presentation we can convert it to a pandas DataFrame\n",
    "- This will allow us the quick access methods of pandas, so that we can iteratively select each column from the dataframe and fit a model for it based on other columns\n",
    "- Then we can import and use any of the sklearn clasifiers, I chose for these tests Naive Bayes, SVM and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix/Data Format\n",
    "- Our matrix is likely going to be a large matrix of 0s and 1s where 1 denotes the existance of this attribute for a specific document\n",
    "- The dimensionality of the matrix will be the number of attributes we predefine for each bot use case (by the number of documents we have available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random matrix of 1s and 0s of dimensionality 10000 x 5\n",
    "matrix = np.random.randint(2, size=(10000, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to data frame and assign generic attribute/entity names\n",
    "df = pd.DataFrame(matrix, columns=['A', 'B', 'C', 'D', 'E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D  E\n",
       "0  0  0  1  1  0\n",
       "1  0  0  0  0  1\n",
       "2  1  0  1  0  0\n",
       "3  0  0  1  0  1\n",
       "4  1  0  0  1  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "- For the models to work we need to have a separation of the input data X and the training output data Y\n",
    "- The main problem arises from the fact that we do not know how many attributes will be provided at a time to use (i.e. predict the value of attribute 'D' based only on the known existence of attributes 'A' and 'B')\n",
    "- Hence, the current solution I propose is to train models for each of the attributes by using as input data all the other attributes and use means to fill in those values which are missing (I'll explain further later)\n",
    "- As shown below, this would mean, for example, that we take the known values of columns A, B, D, E from the training data and fit the model for the attribute 'C'\n",
    "- This way we will have models for predicting the probability of existence for each and every attribute on its ow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the input/output distinction in the training data\n",
    "X, y = df[['A', 'B', 'D', 'E']], df['C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "- Benefit of this model is that it simple and straightforward, using only conditional probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51000558 0.48999442]]\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "# fit the classifier on the training dataset\n",
    "clf.fit(X, y)\n",
    "\n",
    "# predict the Pr(C = ['0' or '1'] | A, B, D, E)\n",
    "print(clf.predict_proba([[1, 1, 1, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "- SVM or SVC (support vector classifier) are effectively at fitting the data and separating them into clear classfication labels, especially when only predicting 0 or 1 like in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# clf = SVC()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# SVM does not support probability prediction, only the value directly\n",
    "print(clf.predict([[1, 0, 0, 1]]))\n",
    "print(clf.predict([[0, 1, 1, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "- Random Forests are proably the most human-understandable approach since they simple use a number of decision trees and splits based on the values/existence of other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52614083 0.47385917]]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.predict_proba([[1, 1, 1, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the execution time for Random Forest for 10000 docs with 5 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "# I wanted to test this to simply validate that the training of these models will be extremely fast since\n",
    "# we are only dealing with a limited dimensionality space (i.e. max 15-20 attributes) and values of 0 and 1\n",
    "%time\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=0)\n",
    "columns = ['A', 'B', 'C', 'D', 'E']\n",
    "for col in columns:\n",
    "    temp = columns.copy()\n",
    "    temp.remove(col)\n",
    "    X, y = df[temp], df[col]\n",
    "    clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the problem of not knowing the values since the bot is an iterative experience (one attribute value after another is obtained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The problem is the fact that at the start we will get either a simple message \"I'd like to create a contract with this and that value of this 'attribute'...\" or just \"I'd like to create a new contract\"\n",
    "- Hence, we need to decide which attribute to ask for (either in which order or based on the limited number of given attribute values)\n",
    "- One solution to this is to train models for each subset of input variables (i.e. train models for only knowing attributes 'A', or 'B', or ['A', 'C'], or ['B', 'C', 'D']\n",
    "- However, while this may produce better results, this will result in an inordinate number of models that need to be trained and retrained (based on my understanding, this will be a factorial expansion, meaning that if there are 10 attributes, we will have to train 10! models which is unreasonable\n",
    "- The other more appropriate solution to this problem is what is often done in ML and that is to use the mean values of the missing attributes with the idea being to fill their values with the most neutral ones for the model (shown below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0.4978\n",
       "B    0.5004\n",
       "C    0.4942\n",
       "D    0.4895\n",
       "E    0.5004\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50010003 0.49989997]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the probability for C based only on the mean values of other attributes\n",
    "print(clf.predict_proba([[0.5106, 0.4937, 0.4953, 0.5033]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the value predicted when using only means will be close to the mean of the original attribute values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with the 'mean values' solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The known problems with this solution is that it essentially assumes a normal distribution of the input values as well as a relative level of inter-independence\n",
    "- However I think that this will not be an issue even if certain attributes are always present and the individual models for each attribute should ensure that if A and B are always together, then whenever A==1, the model should predict B=1 as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing out Random Forest classifier with actual values instead of 0s and 1s... (to be done later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This turned out to be a much more difficult problem than I assumed at first since I need to figure out and research which kind of approach to data labeling and which ML algorithm approach to actually use for this\n",
    "- I'll get back to it next week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
