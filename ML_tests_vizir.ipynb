{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "- We can use numpy darrays to store the matrix\n",
    "- Then for easier access and better presentation we can convert it to a pandas DataFrame\n",
    "- This will allow us the quick access methods of pandas, so that we can iteratively select each column from the dataframe and fit a model for it based on other columns\n",
    "- Then we can import and use any of the sklearn clasifiers, I chose for these tests Naive Bayes, SVM and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix/Data Format\n",
    "- Our matrix is likely going to be a large matrix of 0s and 1s where 1 denotes the existance of this attribute for a specific document\n",
    "- The dimensionality of the matrix will be the number of attributes we predefine for each bot use case (by the number of documents we have available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random matrix of 1s and 0s of dimensionality 10000 x 5\n",
    "matrix = np.random.randint(2, size=(10000, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 1],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to data frame and assign generic attribute/entity names\n",
    "df = pd.DataFrame(matrix, columns=['A', 'B', 'C', 'D', 'E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D  E\n",
       "0  0  1  0  1  1\n",
       "1  0  0  1  0  0\n",
       "2  0  0  0  1  1\n",
       "3  0  0  0  0  0\n",
       "4  0  1  0  0  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "- For the models to work we need to have a separation of the input data X and the training output data Y\n",
    "- The main problem arises from the fact that we do not know how many attributes will be provided at a time to use (i.e. predict the value of attribute 'D' based only on the known existence of attributes 'A' and 'B')\n",
    "- Hence, the current solution I propose is to train models for each of the attributes by using as input data all the other attributes and use means to fill in those values which are missing (I'll explain further later)\n",
    "- As shown below, this would mean, for example, that we take the known values of columns A, B, D, E from the training data and fit the model for the attribute 'C'\n",
    "- This way we will have models for predicting the probability of existence for each and every attribute on its ow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the input/output distinction in the training data\n",
    "X, y = df[['A', 'B', 'D', 'E']], df['C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "- Benefit of this model is that it simple and straightforward, using only conditional probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49847914 0.50152086]]\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "# fit the classifier on the training dataset\n",
    "clf.fit(X, y)\n",
    "\n",
    "# predict the Pr(C = ['0' or '1'] | A, B, D, E)\n",
    "print(clf.predict_proba([[1, 1, 1, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "- SVM or SVC (support vector classifier) are effectively at fitting the data and separating them into clear classfication labels, especially when only predicting 0 or 1 like in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# clf = SVC()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# SVM does not support probability prediction, only the value directly\n",
    "print(clf.predict([[1, 0, 0, 1]]))\n",
    "print(clf.predict([[0, 1, 1, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "- Random Forests are proably the most human-understandable approach since they simple use a number of decision trees and splits based on the values/existence of other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49687753 0.50312247]]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.predict_proba([[1, 1, 1, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the execution time for Random Forest for 10000 docs with 5 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "# I wanted to test this to simply validate that the training of these models will be extremely fast since\n",
    "# we are only dealing with a limited dimensionality space (i.e. max 15-20 attributes) and values of 0 and 1\n",
    "%time\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=0)\n",
    "columns = ['A', 'B', 'C', 'D', 'E']\n",
    "for col in columns:\n",
    "    temp = columns.copy()\n",
    "    temp.remove(col)\n",
    "    X, y = df[temp], df[col]\n",
    "    clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the problem of not knowing the values since the bot is an iterative experience (one attribute value after another is obtained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The problem is the fact that at the start we will get either a simple message \"I'd like to create a contract with this and that value of this 'attribute'...\" or just \"I'd like to create a new contract\"\n",
    "- Hence, we need to decide which attribute to ask for (either in which order or based on the limited number of given attribute values)\n",
    "- One solution to this is to train models for each subset of input variables (i.e. train models for only knowing attributes 'A', or 'B', or ['A', 'C'], or ['B', 'C', 'D']\n",
    "- However, while this may produce better results, this will result in an inordinate number of models that need to be trained and retrained (based on my understanding, this will be a factorial expansion, meaning that if there are 10 attributes, we will have to train 10! models which is unreasonable\n",
    "- The other more appropriate solution to this problem is what is often done in ML and that is to use the mean values of the missing attributes with the idea being to fill their values with the most neutral ones for the model (shown below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0.5028\n",
       "B    0.5005\n",
       "C    0.5038\n",
       "D    0.5020\n",
       "E    0.4978\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50460899 0.49539101]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the probability for C based only on the mean values of other attributes\n",
    "print(clf.predict_proba([[0.5106, 0.4937, 0.4953, 0.5033]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the value predicted when using only means will be close to the mean of the original attribute values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with the 'mean values' solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The known problems with this solution is that it essentially assumes a normal distribution of the input values as well as a relative level of inter-independence\n",
    "- However I think that this will not be an issue even if certain attributes are always present and the individual models for each attribute should ensure that if A and B are always together, then whenever A==1, the model should predict B=1 as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out Random Forest classifier with actual values instead of 0s and 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The main difficulty in dealing with actual values arises from the fact that most ML models do not deal well with non-numerical values\n",
    " - The standard and fairly effective solution to this problem is based in encoding of the categorical values (while leaving numerical ones as they are)\n",
    " - There are 2 main approachoes to encoding of the values:\n",
    " - 1) One-Hot encoding where each possible value of the categorical feature is encoding with a binary 0 (missing) or 1 (exists). However, this is probably not the best approach for our use case since the number of possible categorical values might be quite high for certain attributes and hence this would leave to an immensely large (and very sparse) matrix\n",
    " - 2) The solution I implement below and use is encoding each of the categorical values to a corresponding numerical values meaning that the matrix with actual values can then be transformed to a 'numerical' matrix and transformed back when actual results are necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firstly, let us create some test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['France', 'EUR', 'Insurance'],\n",
       " ['UK', 'GBP', 'Insurance'],\n",
       " ['France', 'EUR', 'Contract'],\n",
       " ['France', 'EUR', 'Contract'],\n",
       " ['Switzerland', 'CHF', 'Contract'],\n",
       " ['Switzerland', 'CHF', 'Contract'],\n",
       " ['UK', 'GBP', 'Insurance']]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [['France', 'EUR', 'Insurance'], ['UK', 'GBP', 'Insurance'], ['France', 'EUR', 'Contract'], ['France', 'EUR', 'Contract'], ['Switzerland', 'CHF', 'Contract'], ['Switzerland', 'CHF', 'Contract'], ['UK', 'GBP', 'Insurance']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['Country', 'Currency', 'Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[['Country', 'Currency']], df['Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the sklearn library to perform label encoding (transforming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_country = LabelEncoder()\n",
    "encoder_currency = LabelEncoder()\n",
    "encoderY = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Country'] = encoder_country.fit_transform(X['Country'])\n",
    "X['Currency'] = encoder_currency.fit_transform(X['Currency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoderY.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Currency\n",
       "0        0         1\n",
       "1        2         2\n",
       "2        0         1\n",
       "3        0         1\n",
       "4        1         0\n",
       "5        1         0\n",
       "6        2         2"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing how to decode back to the original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'UK', 'France', 'France', 'Switzerland', 'Switzerland',\n",
       "       'UK'], dtype=object)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_country.inverse_transform(X['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Insurance', 'Insurance', 'Contract', 'Contract', 'Contract',\n",
       "       'Contract', 'Insurance'], dtype=object)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoderY.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below, I simply test the classic Random Forest classifier by training it on test data and predicting the actual expected value for the 'Type' of the document based on the values of 'Country' and 'Currency' columns\n",
    "- The model/algorithm itself works only with numberical values and hence it is very generalizable and effective\n",
    "- But using the saved encoders from before we can encode new incoming data, use the algorithm to predict the value, and then decode the predicted value to the actual 'human-readable' original format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=0)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [1, 1]\n",
    "clf.predict([test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_encoding = [encoder_country.transform(['France'])[0], encoder_currency.transform(['EUR'])[0]]\n",
    "test_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Contract'], dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_encoded = clf.predict([test_encoding])\n",
    "encoderY.inverse_transform(result_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
